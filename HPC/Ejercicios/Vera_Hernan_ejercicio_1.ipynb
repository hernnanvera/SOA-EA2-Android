{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vera_Hernan_ejercicio_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1eVFdvGkG5k"
      },
      "source": [
        "# 1 Introducción\n",
        "\n",
        "Las funciones BLAS( Basic Linear Algebra Subprograms) es una especificación que define un conjunto de rutinas de bajo nivel para realizar operaciones comunes del álgebra lineal, como la suma de vectores, multiplicación escalar, combinaciones lineales, y multiplicación de matrices.\n",
        "\n",
        "Una de estas funciones es la función swap. Esta funcion se encarga de intercambiar los valores entre dos vectores del mismo tamaño. Es decir los valores de un vector x pasarán al vector y, y los valores del vector y pasarán al vector x.\n",
        "\n",
        "Para su implementación en cpu se hizo uso de un for donde se recorre el vector x, se guarda el elemento que se va a intercambiar en un auxiliar, y luego se pisa con el valor del elemento en y. Finalmente se guarda en y el valor del auxiliar.\n",
        "\n",
        "Para su implementacion en gpu el algoritmo es similar, solo que en lugar de usar un for se utiliza hilos, donde podremos ver que tendremos una ventaja en el tiempo de ejecucion\n",
        "\n",
        "Dicha funcion swap recibe 1 parametro en su implementacion en cpu. Este parametro es la cantidad de elementos en los vectores.\n",
        "\n",
        "Para su implementacion en GPU la funcion que se va a ejecutar en el mismo recibe como parámetro un entero con la cantidad de elementos de los vectores, y dos punteros, uno al vector x y el otro al vector y.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3dfOwBJjt7E"
      },
      "source": [
        "# 2 Armado del ambiente\n",
        "Instalar en el cuaderno el módulo CUDA de Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF4DX80BEkjP",
        "outputId": "b4972677-f5ba-432b-bee5-6ec47204e567"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "  Using cached https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz\n",
            "Collecting pytools>=2011.2\n",
            "  Using cached https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "  Using cached https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=620775 sha256=a7b40123065403c38a03346b3cee7bd4f736b6a5efdcbf47ef0aeacf6081f7f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=e3d41184b8fb0d651a9dd8639f0afae8bb6c746560a902a2f312ac677552e89f\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czNQvrjDc_o4"
      },
      "source": [
        "#3 Desarrollo\n",
        "\n",
        "En CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO8JQxMHzWYU",
        "outputId": "b31c30b8-4be3-4a85-f997-eba16c1a5def"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "n_elementos =   10#@param {type: \"number\"}\n",
        "\n",
        "\n",
        "#los elementos no pueden ser negativos\n",
        "try:\n",
        "  if n_elementos > 0 :\n",
        "\n",
        "    # --------------------------------------------\n",
        "\n",
        "    from datetime import datetime\n",
        "\n",
        "    tiempo_total = datetime.now()\n",
        "\n",
        "    import numpy\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # Definición de función que transforma el tiempo en  milisegundos \n",
        "    tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # CPU - Defino la memoria de los vectores en cpu.\n",
        "    vec_x_cpu = numpy.random.randn( n_elementos )\n",
        "    vec_x_cpu = vec_x_cpu.astype( numpy.float32() )\n",
        "\n",
        "    vec_y_cpu = numpy.random.randn( n_elementos )\n",
        "    vec_y_cpu = vec_y_cpu.astype( numpy.float32() )\n",
        "\n",
        "    #muestro los vectores antes de intercambiarlo\n",
        "\n",
        "    print(\"------------------------------------\")\n",
        "    print( \"Vectores antes del intercambio\" )\n",
        "    print( \"Vector X\" )\n",
        "    print(vec_x_cpu)\n",
        "    print( \"Vector Y\" )\n",
        "    print(vec_y_cpu)\n",
        "    print(\"------------------------------------\")\n",
        "\n",
        "    # CPU - Realizo la función swap.\n",
        "    tiempo_bucle = datetime.now()\n",
        "\n",
        "    for i in range( 0, n_elementos ):\n",
        "      aux = vec_x_cpu[i]\n",
        "      vec_x_cpu[i] = vec_y_cpu[i]\n",
        "      vec_y_cpu[i] = aux\n",
        "\n",
        "    tiempo_bucle = datetime.now() - tiempo_bucle\n",
        "\n",
        "    # --------------------------------------------\n",
        "\n",
        "    print(\"------------------------------------\")\n",
        "    print( \"Vectores despues del intercambio\" )\n",
        "    print( \"Vector X\" )\n",
        "    print(vec_x_cpu)\n",
        "    print( \"Vector Y\" )\n",
        "    print(vec_y_cpu)\n",
        "    print(\"------------------------------------\")\n",
        "\n",
        "\n",
        "    tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "    print(\"Tiempo Total: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "    print(\"Tiempo bucle: \", tiempo_en_ms( tiempo_bucle ), \"[ms]\" )\n",
        "  else:\n",
        "    print(\"Solo se permiten numeros mayores a cero\")\n",
        "except Exception as e:\n",
        "  print(\"Tipo de excepcion: \", type(e))\n",
        "  print(\"Detalles:: \", e.args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------\n",
            "Vectores antes del intercambio\n",
            "Vector X\n",
            "[ 0.18534938  0.64922297 -1.3895415  ...  1.5925095   0.5476027\n",
            " -0.4416843 ]\n",
            "Vector Y\n",
            "[ 0.9207951   0.5725047  -1.787129   ...  0.01042973  0.17937021\n",
            "  0.24206498]\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "Vectores despues del intercambio\n",
            "Vector X\n",
            "[ 0.9207951   0.5725047  -1.787129   ...  0.01042973  0.17937021\n",
            "  0.24206498]\n",
            "Vector Y\n",
            "[ 0.18534938  0.64922297 -1.3895415  ...  1.5925095   0.5476027\n",
            " -0.4416843 ]\n",
            "------------------------------------\n",
            "Tiempo Total:  4.824 [ms]\n",
            "Tiempo bucle:  2.407 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtaHYLyZ2R1w"
      },
      "source": [
        "En GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1TmMoSAN8uo",
        "outputId": "a200890b-3a33-46c7-930d-5f074faca277"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "n_elementos =   10#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "try:\n",
        "  if n_elementos > 0 :\n",
        "\n",
        "    from datetime import datetime\n",
        "\n",
        "    tiempo_total = datetime.now()\n",
        "\n",
        "    import pycuda.driver as cuda\n",
        "    import pycuda.autoinit\n",
        "    from pycuda.compiler import SourceModule\n",
        "\n",
        "    import numpy\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # Definición de función que transforma el tiempo en  milisegundos \n",
        "    tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "\n",
        "    # CPU - Defino la memoria de los vectores en cpu.\n",
        "    vec_x_cpu = numpy.random.randn( n_elementos )\n",
        "    vec_x_cpu = vec_x_cpu.astype( numpy.float32() )\n",
        "\n",
        "    vec_y_cpu = numpy.random.randn( n_elementos )\n",
        "    vec_y_cpu = vec_y_cpu.astype( numpy.float32() )\n",
        "\n",
        "    #muestro los vectores antes de intercambiarlo\n",
        "    print(\"------------------------------------\")\n",
        "    print( \"Vectores antes del intercambio\" )\n",
        "    print( \"Vector X\" )\n",
        "    print(vec_x_cpu)\n",
        "    print( \"Vector Y\" )\n",
        "    print(vec_y_cpu)\n",
        "    print(\"------------------------------------\")\n",
        "\n",
        "\n",
        "    # CPU - reservo la memoria GPU.\n",
        "    vec_x_gpu = cuda.mem_alloc( vec_x_cpu.nbytes )\n",
        "    vec_y_gpu = cuda.mem_alloc( vec_y_cpu.nbytes )\n",
        "\n",
        "    # GPU - Copio la memoria al GPU.\n",
        "    cuda.memcpy_htod( vec_x_gpu, vec_x_cpu )\n",
        "    cuda.memcpy_htod( vec_y_gpu, vec_y_cpu )\n",
        "\n",
        "    # CPU - Defino la función kernel que ejecutará en GPU.\n",
        "    module = SourceModule(\"\"\"\n",
        "    __global__ void kernel_swap( int n, float *X, float *Y )\n",
        "    {\n",
        "      int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "      float aux;\n",
        "      if( idx < n )\n",
        "      {\n",
        "        aux = X[idx];\n",
        "        X[idx] = Y[idx];\n",
        "        Y[idx] = aux;\n",
        "      }\n",
        "    }\n",
        "    \"\"\") \n",
        "    # CPU - Genero la función kernel.\n",
        "    kernel = module.get_function(\"kernel_swap\")\n",
        "\n",
        "    tiempo_gpu = datetime.now()\n",
        "\n",
        "    # GPU - Ejecuta el kernel.\n",
        "    dim_hilo = 256\n",
        "    dim_bloque = numpy.int( (n_elementos+dim_hilo-1) / dim_hilo )\n",
        "    print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "\n",
        "    kernel( numpy.int32(n_elementos), vec_x_gpu, vec_y_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "\n",
        "    tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "    # GPU - Copio el resultado desde la memoria GPU.\n",
        "    cuda.memcpy_dtoh( vec_x_cpu, vec_x_gpu )\n",
        "    cuda.memcpy_dtoh( vec_y_cpu, vec_y_gpu )\n",
        "\n",
        "    print(\"------------------------------------\")\n",
        "    print( \"Vectores despues del intercambio\" )\n",
        "    print( \"Vector X\" )\n",
        "    print(vec_x_cpu)\n",
        "    print( \"Vector Y\" )\n",
        "    print(vec_y_cpu)\n",
        "    print(\"------------------------------------\")\n",
        "\n",
        "    tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "    print( \"Cantidad de elementos: \", n_elementos )\n",
        "    print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "    print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "    print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n",
        "  else:\n",
        "    print(\"Solo se permiten numeros mayores a cero\")\n",
        "except Exception as e:\n",
        "  print(\"Tipo de excepcion: \", type(e))\n",
        "  print(\"Detalles:: \", e.args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------\n",
            "Vectores antes del intercambio\n",
            "Vector X\n",
            "[ 2.1219563  -0.3426045   1.4899883  ... -0.21549508  1.3003734\n",
            "  0.8261049 ]\n",
            "Vector Y\n",
            "[ 0.41537946  1.8969617  -0.563673   ...  2.6963785  -2.6652527\n",
            " -0.37479302]\n",
            "------------------------------------\n",
            "Thread x:  256 , Bloque x: 20\n",
            "------------------------------------\n",
            "Vectores despues del intercambio\n",
            "Vector X\n",
            "[ 0.41537946  1.8969617  -0.563673   ...  2.6963785  -2.6652527\n",
            " -0.37479302]\n",
            "Vector Y\n",
            "[ 2.1219563  -0.3426045   1.4899883  ... -0.21549508  1.3003734\n",
            "  0.8261049 ]\n",
            "------------------------------------\n",
            "Cantidad de elementos:  5000\n",
            "Thread x:  256 , Bloque x: 20\n",
            "Tiempo CPU:  1145.251 [ms]\n",
            "Tiempo GPU:  2.775 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8T4PPDtRZ2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tADGVwiTnm7c"
      },
      "source": [
        "# 4 Tabla de pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arkVj6wTn0FL"
      },
      "source": [
        "# 4.1 En CPU\n",
        "\n",
        "Procesador | Función | Detalle\n",
        "---------- | -------   | -------\n",
        "CPU        | @param   | Tamaño del los vecotores x e y\n",
        "CPU        | import | Importa los modulos necesarios para el correcto funcionamiento\n",
        "CPU        | datetime.now() |\tToma el tiempo inicial.\n",
        "CPU        | numpy.random.randn( n_elementos ) | Inicializa los vectores x e y\n",
        "CPU        | for...| Realiza el intercambio entre los vectores x e y\n",
        "CPU        | datetime.now() | Toma el tiempo final\n",
        "CPU        | print() | Muestra los vectores intercambiados por pantalla\n",
        "CPU        | print() | Muestra los resultados de la ejecución por pantalla\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAV4XHifn5lD"
      },
      "source": [
        "# 4.2 En GPU\n",
        "Procesador | Función | Detalle\n",
        "---------- | -------   | -------\n",
        "CPU        | @param   | \tLectura del tamaño de vectores x e y desde Colab\n",
        "CPU        | import | Importa los modulos necesarios para el correcto funcionamiento\n",
        "CPU        | datetime.now() |\tToma el tiempo inicial.\n",
        "CPU        | numpy.random.randn( n_elementos ) | Inicializa los vectores x e y\n",
        "GPU        | cuda.mem_alloc() | Reserva la memoria en GPU\n",
        "GPU        | cuda.memcpy_htod() | Copia las memorias desde el CPU al GPU.\n",
        "CPU        | SourceModule() |\tDefine el código del kernel\n",
        "CPU        | module.get_function() | Genera la función del kernel GPU\n",
        "CPU        | dim_tx/dim_bx | Calcula las dimensiones\n",
        "GPU        | kernel() | Ejecuta el kernel en GPU\n",
        "CPU        | cuda.memcpy_dtoh( ) | Copia el resultado desde GPU memoria A a CPU memoria R.\n",
        "CPU        | print() | Muestra los vectores intercambiados por pantalla\n",
        "CPU        | print() | Muestra los resultados de la ejecución por pantalla"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEaiSukkn-cl"
      },
      "source": [
        "# 5 Conclusiones\n",
        "\n",
        "Podemos ver que los tiempos de ejecucion utilizando CUDA, y un tamaño de vecotres de 5000 elementos, son mucho menor que utilizando la cpu de manera secuencial. Esto debido a que usamos la ventaja que nos da la implementacion de hilos, ya que se generará uno por cada elemento del vector, acelerando el proceso de intercambio entre vectores. No siempre es mejor la implementacion en hilos, puede ser que haya operaciones que dependan de otras para terminar, o que implementar hilos hace que la creacion de los mismos , su uso, y toda su estructura implique mayor costo que luego se refleja en los tiempos de ejecución, y asi puede llegar a ocurrir el caso en el que una implementacion secuencial saca mejor provecho que en paralelo. Esto pasa en el caso donde la entrada ( la cantidad de elementos) no es tan grande.\n",
        "\n",
        "Para CPU: \n",
        "Tiempo Total:  9.875 [ms]\n",
        "\n",
        "Para GPU:\n",
        "Tiempo Total:  6.420 [ms]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlxkcEQCoEA9"
      },
      "source": [
        "# 6 Bibliografía\n",
        "\n",
        "[1] LBLAS Technical Forum: [Referencia](http://netlib.org/blas/blast-forum/)\n",
        "\n",
        "[2] Developer Reference for Intel® Math Kernel Library - C: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions.html)\n",
        "\n",
        "[3] GPU Accelerated Computing with Python: [Referencia](https://developer.nvidia.com/how-to-cuda-python)\n",
        "\n",
        "[4] PyCUDA Documentation: [Referencia](https://documen.tician.de/pycuda/)"
      ]
    }
  ]
}